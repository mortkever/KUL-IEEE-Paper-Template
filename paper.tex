\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[backend=biber, style=ieee, 
citestyle=numeric-comp, maxnames=50, maxcitenames=1]{biblatex}
\addbibresource{bib.bib}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage[acronym,xindy]{glossaries}
\makenoidxglossaries
\input{abbreviations.tex}
\begin{document}

\title{PTAsan: Detecting Unsoundness in Pointer Analysis Results\\
{\footnotesize The Unharmonious Truth of Unsound Pointer Analysis}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Victor Deforce}
    \IEEEauthorblockA{\textit{Distrinet} \\
        \textit{KULeuven}\\
        Gent België \\
        r0793705@kuleuven.be}
    \and
    \IEEEauthorblockN{2\textsuperscript{nd} Adriaan Jacobs}
    \IEEEauthorblockA{\textit{Distrinet} \\
        \textit{KULeuven}\\
        Gent België \\
        adriaan.jacobs@kuleuven.be}
    \and
    \IEEEauthorblockN{3\textsuperscript{rd} Anton Schelfthout}
    \IEEEauthorblockA{\textit{Distrinet} \\
        \textit{KULeuven}\\
        Gent België \\
        anton.schelfthout@kuleuven.be}
        \and
    \IEEEauthorblockN{4\textsuperscript{th} Alicia Andries}
    \IEEEauthorblockA{\textit{Distrinet} \\
        \textit{KULeuven}\\
        Gent België \\
        alicia.andries@kuleuven.be}
    \and
    \IEEEauthorblockN{5\textsuperscript{th} Stijn Volckaert}
    \IEEEauthorblockA{\textit{Distrinet} \\
        \textit{KULeuven}\\
        Gent België \\
        stijn.volckaert@kuleuven.be}
}

\maketitle

\begin{abstract}
    Een heel aantal toepassingen maken gebruik van pointer analysis: compiler optimization, Data Flow Integrity (DFI), control flow integrity, compartmentalization, etc. 
Hoewel het algemeen bekend is dat deze analyses een overschatting zijn, staat men er zelden bij stil dat de analyse ook points-to sets kan ónderschatten. Deze onderschatting 
van points-to sets door 
deze tools is nefast voor toepassingen zoals DFI en compartmentalization. Deze toepassingen steunen
op de overschatting van de set van adressen, die een lees- of schrijfinstructie kan benaderen, met
crashes op willekeurige momenten tot gevolg als dit niet zo is.
Er is geen nut aan veiligheidsmechanismes zoals DFI, als ze random crashes veroorzaken doordat de 
points-to sets te beperkend zijn.
Er is dus een
duidelijke kloof tussen ontwikkelaars van deze pointer analysis tools, die de veronderstellingen en
limieten in hun implementatie kennen, en de ontwikkelaars die deze tools gebruiken in hun
toepassingen. 

In deze thesis hebben we de PTAsan, Pointer Analysis sanitizer, ontwikkeld om de
aanwezigheid van unsoundness in veel gebruikte pointer analyses empirisch te meten. De PTAsan
geeft ons inzicht in de oorzaak van de unsoundness via uitgebreide logging. We hebben de PTAsan
geïmplementeerd als een DFI-like controlesysteem en we instrumenteren testcode door middel van
LLVM. We hebben o.a. de Andersen pointer analysis van SVF getest op de SPEC CPU2006
benchmarking suite en vastgesteld dat tot 2\% van de points-to sets unsound zijn. Aangezien grotere
programma's zoals GCC bestaan uit meer dan honderdduizend points-to sets, zorgt dit voor
onpraktisch veel crashes in bijvoorbeeld DFI. We hebben manueel enkele van deze bronnen van
unsoundness opgespoord en gerapporteerd aan de ontwikkelaars van SVF.
\end{abstract}

\begin{IEEEkeywords}
    Pointer analysis, data-flow integrity, SVF, Soundness, soundiness
\end{IEEEkeywords}

\section{Introductie}
Dezelfde vrijheid die pointers geeft in C en C++ zorgt er ook voor dat programma's geschreven in deze taal gevoelig zijn voor aanvallen met geheugen exploits. 
Doorheen de jaren zijn tal van oplossingen uitgewerkt waaronder \gls{dfi}\cite{castro_securing_nodate} en WIT\cite{akritidis_preventing_2008}. \gls{dfi} bepaalt 
statisch, met een pointer analyse, voor elke lees en schrijf instructie de (points-to) set van objecten die deze instructie zal kunnen benaderen onder normale 
omstandigheden. Terwijl het programma loopt, dwingt \gls{dfi} deze sets af door het programma te laten crashen indien de instructie benadert dat niet in de set zit. 
Als bijvoorbeeld een aanvaller de normale verloop van het programma probeert te wijzigen door return adressen te overschrijven, dan zal \gls{dfi} dit detecteren en 
de aanval afwenden.

Om dus een goede werking te garanderen mag de statische analyse geen onderschatting maken van de objecten in de points-to set. Als analyse objecten mist in de set kan 
dit leiden tot spontane crashes in het programma wanneer er geen aanval gaande is. Hoewel dat ontwikkelaars die deze analyses gebruiken zich over het algemeen bewust 
van de overschattingen die een pointer analyse maakt, staat men er zelden bij stil dat de analyse ook sets kan onderschatten.
Pointer analyses worden in vele toepassingen gebruikt. We delen ze daarom hier op in twee groepen. Voor de eerste groep gebruiken we de term \textbf{offensieve pointer analyse}.
Deze analyses worden voornamelijk gebruikt voor allerhande bug-detectie tools: memory leaks, ongeïnitialiseerde variabelen, 
etc.\cite{sui_svf_nodate}\cite{cherem_practical_nodate}\cite{ye_accelerating_nodate}. Daarnaast zijn er, wat Smaragdakis\cite{smaragdakis_defensive_2018} noemt 
\textbf{defensieve pointer analysis}. Deze worden gebruikt o.a.\ door \gls{dfi}\cite{castro_securing_nodate}\cite{diez-franco_optimized_2024}, 
\gls{cfi}\cite{kasten_integrating_2024}\cite{li_finding_2020} en een aantal compiler optimalisaties\cite{hind_interprocedural_1999}. 

We maken het onderscheid tussen deze twee groepen aangezien hun verwachtingen loodrecht op elkaar staan. Voor bijvoorbeeld het detecteren van memory leaks heeft men 
een analyse nodig die snel en precies is\cite{cherem_practical_nodate}\cite{fan_smoke_2019}. Want de analyse draait mogelijks in de IDE en men ziet liefst zo weinig 
mogelijk foute rapporteringen. Het is minder relevant dat de detector enkele leaks mist, aangezien de resultaten in vergelijking met andere implementaties worden gepubliceerd.
Een analyse die hier aan voldoet noemen we een offensieve analyse.

Toepassingen die een defensieve pointer analyses gebruiken zoals \gls{dfi}, verwachten ook een zekere precisie maar steunen op de garantie dat de sets niet onderschat zijn en dus 
sound zijn. Zoals eerder vermeld leidt een onderschatting van de sets tot een analyse die niet functioneert. We gebruiken dan ook de term defensief om te duiden welke garanties deze 
analyses zouden moeten stellen. Voor zover wij weten, bestaan er slechts drie analyses die beweren defensief te zijn.\cite{smaragdakis_defensive_2018}\cite{cai_unleashing_nodate}\cite{lu_practical_2023}

Hoewel het aantal defensieve analyses beperkt is en de ontwikkelaars zich wel bewust zijn van de beperkingen in hun implementaties\cite{vojnar_phasar_2019}, beseffen weinig 
developers die de analyses gebruiken dat deze sound zijn. Vele zijn dus overhead en compatibiliteits problemen als de voornaamste obstakels\cite{mathiasen_fine-grained_2021}\cite{bellec_rt-dfi_2022}\cite{diez-franco_optimized_2024}\cite{feng_toward_2022} 
voor \gls{dfi} buiten de onderzoekswereld gebruikt kan worden. Echter zonder sound pointer analyse, zal \gls{dfi} voor random crashes blijven zorgen en dus niet ingezet worden.

Om voor unsoundness te corrigeren voegen sommigen developers van toepassingen een profiling phase toe aan hun implementatie\cite{jin_annotating_2022}\cite{kirth_pkru-safe_2022}.
In deze fase voegen gemiste objecten toe aan de sets tijdens test runs om zo crashes te vermijden tijdens de benchmarks. Dynamische analyses hebben echter een coverage probleem 
want met de test cases waarmee het programma is getest, kan men zelden het volledige gedrag van het programma opbouwen. Het programma is dus sound voor de testcases maar 
waarschijnlijk niet voor andere inputs.

In het soundiness manifesto\cite{livshits_defense_2015} doet een groep van pointer analysis onderzoekers een oproep voor meer 
transparantie. Ze stellen dat soundness een afweging vereist met precisie en schaalbaarheid. Bepaald gedrag in een programma, 
zoals pointer arithmetic, maken het moeilijk om precies de points-to sets van een pointer te bepalen. Men stelt dus de term 
soundiness voor, het sound behandelen van de meeste language features maar het bewust onderschatten van sets voor zekere 
ver onderzochte feature set. 

Om de verregaande aanwezigheid van unsoundness empirisch te bewijzen en te quantificeren hebben we PTAsan ontwikkeld, pointer analysis 
sanitizer. Onze implementatie laat ons toe alle fouten in de points-to set voor een gegeven test programma te loggen en de oorzaak terug 
te volgen tot aan zijn bron. 

\section{Achtergrond}

\subsection{Betekenis van soundness}
In het Engels kunnen de termen sound of soundness gebruikt worden om aan te geven dat iets correct werkt. Afhankelijk van de verwachtingen die men stelt kan hetzelfde dus tegelijk sound en unsound zijn. Zoals in de inleiding al aangegeven kan er een onderscheid in points-to analyses gemaakt worden tussen defensieve en offensieve. Afhankelijk van de categorie kan een resultaat hier dus ook sound of unsound zijn.

Voor offensieve analyses is het doel om precise sets af te leveren die dus een zo klein mogelijke overschatting maken. Als de set meer objecten bevat dan dat werkelijk mogelijk is, duiden mogelijk toepassingen zoals bug-detectie fouten aan waar er geen zijn. Voor de eindgebruiker is dit niet gewenst. Een analyse die teveel overschatting doet in de sets kan men dus als unsound beschouwen.

Voor defensieve analyses is het van belang dat de set exhaustief is. Voor bijvoorbeeld \gls{dfi} zorgt een overschatting dat de veiligheidsgaranties minder sterk zijn, een onderschatting maakt echter het veiligheidsmechanisme rechtuit onbruikbaar. Een defensieve analyse is dus enkel sound als deze geen onderschatte sets als resultaat levert. Dit is al duidelijk in sterk contrast met de offensieve analyses. 

Verder kan de nuance dieper worden doorgetrokken op vlak defensieve analyses. C en C++ laten de programmeur veel vrijheid. Hoe defensief een analyse is kan dus afgemeten worden aan de hand van de bizarre, door programmeurs bedachte, constructies die nog door de analyse sound worden afgehandeld. 

Men zou bijvoorbeeld typisch een access van één object via de pointer van een ander object beschouwen als een memory error. Echter sommige programmeurs passen volgende techniek toe. Ze berekenen de offset tussen de adressen van twee objecten en slaan deze op. Op een later moment gebruiken ze deze offset en de pointer van één van de twee objecten om het andere object te benaderen. Dit noemt men relative pointers. 

Een ander fenomeen waar men op de site van het soundiness manifesto\cite{noauthor_soundiness_nodate} voor bewustzijn voor pleit, is mogelijke buffer overflows. Naar onze mening is dit buiten het correct gedrag van het programma en hoort een analyse hier dus geen rekening mee te nemen. Het sound verwerken van dit fenomeen zou echter de analyse een meer sound resultaat doen geven in relatie tot de reële werking van het programma. 

\subsection{Cascades van unsoundness}

De bron van unsoundness kan ook unsoundness zijn. In deze zin heeft kan een unsound set een cascade effect hebben op andere sets. Dit is het gemakkelijkst te zien bij sets van struct pointers en function pointers. Zo kan een struct met een function pointer als field ontbreken uit de set van een pointer en dan zal de functie ook ontbreken in de sets van de pointers die gelijk worden gesteld aan die function pointer via de struct pointer. Andersom kan een function pointer ook ontbreken in de set van de operand van een call. Logischerwijs zitten de elementen uit de sets van de meegegeven argumenten niet in de sets van de parameters van die functie. 

Aan deze gevallen kunnen we zien dat het traceren van de bron van unsoundness niet alleen neerkomt op het vinden van de oorzaak 
Aan deze gevallen is te zien dat een zinvolle analyse niet alleen ons helpt de bron van unsoundness te vinden maar dat deze ook de eerste oorzaak van unsoundness vindt. Unsound accesses na de eerste unsound access kunnen ook de oorzaak zijn van problemen in de analyse maar enkel voor de eerste is gegarandeerd dat de oorzaak van de unsoundness niet bij andere unsoundness ligt.


\section{Implementatie}
In deze paper leggen de werking uit van PTAsan, de points-to analysis sanitizer. Met PTAsan hebben we als doel het aantal fouten in points-to analysis tools op te meten en voldoende informatie te verzamelen om de oorsprong van deze fouten op te sporen. We doen dit door middel van een door \gls{dfi} en \gls{cfi} geïnspireerde implementatie.

\subsection{PTAsan DFI}
Zoals bij \gls{dfi} bestaat PTAsan uit een compiletime component en een runtime component. At compiletime laten we de te testen points-to analysis de points-to sets opstellen voor de test case. Op basis van deze sets instrumenteren we dan zelf verder het test programma. 

Om elementen uit de sets duidelijk te linken met hun runtime equivalent geven we elk element een uniek kleur. We weten namelijk niet at compiletime waar een specifiek object gealloceerd zal worden en kunnen dus pas at runtime een kleur toekennen aan een specifiek stuk geheugen. Aangezien elk element in een set slaat op een unieke allocation site, niet een uniek object, kunnen we achter elke allocation site een coloring functie invoegen. Deze kleuren zijn 16-bit integers en worden deterministisch toegekend om het traceren van unsoundness te vereenvoudigen.

Deze manier van instrumenteren is geschikt voor statische en dynamische allocaties, echter voor globals die niet worden gealloceerd hebben we een andere aanpak nodig. Voor deze injecteren we een volledig nieuwe functie in de test code. In deze code roepen we voor elke global in het programma de coloring functie op. 

Naast het kleuren van alle allocatie sites, controleren we ook de kleur van een object bij een memory access. We voegen hiervoor ook een function call toe. Aan de color check functie geven we het adres mee van het object en de set van kleuren mee die overeen komen met points-to set van de pointer operand van de access. Verder geven we ook een uniek id mee om unsound accesses te kunnen linken aan de instructie. In de functie verifiëren we of de kleur van het object in de set zit. Als dit het geval is keert de controle terug naar het programma, als dit niet het geval is loggen we de unsound access door middel van de kleur van het object en de id van de instructie.

%Functies uit dynamisch gelinkte libraries kunnen we niet instrumenteren. Hoewel we wel dynamische allocaties instrumenteren, die ook binnen deze categorie vallen, weten we alleen 
Om deze mechanismen te ondersteunen implementeren een aantal functies en datastructuren door middel van een library. De voornaamste data structuur is de color table. Deze bevat voor elke blok van 16 bytes een color. Deze granulariteit is in lijn met minimum grootte van een heap allocated object. Verder definiëren ook een initialisatie functie met constructor attribuut die de color table alloceert alsook de global coloring functie aanroept. Door het constructor attribuut wordt deze functie uitgevoerd voor de main van het test programma. Dit garandeert dat alle setup gebeurd is voor de eerste instructie van het programma zelf wordt uitgevoerd.

Daarnaast bevat onze library ook code om te differentiëren tussen kleurloze objecten. Alleen allocation sites die element zijn van een set krijgen een kleur. Als de points-to analysis dus een bepaalde allocation site niet herkent dan kleuren we deze niet. Dit is voornamelijk een risico bij externe library functies glibc. Deze libraries worden dynamisch gelinkt dus at compiletime is de sourcecode niet beschikbaar. Om dit op te lossen houdt *** (naar background?) een analyse een karakterisatie bij van het pointer gedrag in de deze functie. Echter als deze karakterisering fout is opgesteld, dan kan dit tot unsoundness leiden. Bijvoorbeeld malloc geeft een pointer terug naar nieuw gealloceerd geheugen. Met een foute karakterisering of zelfs met een gebrek aan, ziet de pointer analyse elke malloc niet als een allocation site. 

Via allocator interposition kunnen we het onderscheid maken tussen allocaties door externe libraries (dynamic allocations) en door andere methoden. Aangezien statisch gelinkte functies eerst gebruikt worden, kunnen we zelf functies definiëren met de naam malloc, calloc, etc. In deze functie kunnen we, als de oorspronkelijke call extern was, een deel van de stacktrace registreren. Het bestaan van deze trace bij een latere unsound access toont dat het object extern gealloceerd was. Als de callchain tussen de eerste externe call en de allocatie niet te groot is kan uit de trace ook worden afgeleid welke functie verkeerd is gekarakteriseerd door de points-to analysis. In de huidige implementatie is deze slechts 1 call hoog.

\subsection{PTAsan CFI}
Aangezien unsoundness een cascade effect kan hebben op de resultaten en control flow geen aspect is dat getest wordt onder de \gls{dfi} kant van PTAsan, hebben we een \gls{cfi} kant aan PTAsan toegevoegd. Deze detecteert fouten in het sets van function pointers. De combinatie van beide kanten garandeert ons dat we steeds het eerste soundness issue detecteren.

We implementeren de \gls{cfi} analoog aan de \gls{dfi} kant. We laten de points-to analyse de points-to set opstellen voor elke functie pointer. We kennen aan elke address-taken functie een unieke kleur toe en we injecteren voor elke indirecte call een call naar de color check functie. At runtime wordt de color table gealloceerd en kleuren we direct de functies zoals we oo direct de globals kleuren bij opstart aan \gls{dfi} kant. Voor iedere indirect call controleren we of de opgeroepen functie in de set van de pointer zit. 

\section{Resultaten} 

Ons doel is om unsoundness te detecteren in de output van pointer analysis tools. Om zeker te zijn dat unsoundness die we detecteren geen product is van foute of kwaadaardige input, gebruiken we de SPEC CPU2006 benchmarking suite. Deze suite bestaat uit een verzameling van programma's met voor elk een aantal geldig test inputs. Deze programma's kunnen memory errors bevatten. Deze errors zullen dus ook als unsoundness aanzien als de analyse hier geen rekening mee houdt. 

We hebben onze sanitizer getest op SVF versies 2.5 en 3.0 met de Andersen implementatie. SVF is een veel gebruikte program analysis tool\cite{kasten_integrating_2024}\cite{guo_bulkhead_2025}\cite{huang_taming_2022} waarbij anderen al hebben ondervonden dat deze unsound is\cite{kasten_integrating_2024}. 

We lieten onze test lopen op een Intel(R) Xeon(R) Silver 4116 CPU with 125GB RAM met Linux 6.12.33\-061233\-generic x86\_64.

\begin{table}[htbp]
    \begin{center}
\begin{tabular}{|l|rr|r|}
\hline
Programs       & Unsound sets & Empty sets & Total \# sets \\ 
\hline
\hline
Benchmark.ll   & 0   & 0     & 11550 \\ 
401.bzip2      & 0   & 92    & 2587  \\ 
429.mcf        & 0   & 1     & 471   \\ 
444 namd       & 0   & 205   & 6106  \\ 
462.libquantum & 0   & 2     & 245   \\ 
470 lbm        & 0   & 5     & 281   \\ 
473 astar      & 4   & 82    & 1353  \\ 
458 sjeng      & 19  & 5     & 2738  \\ 
464 h264ref    & 24  & 650   & 35701 \\ 
471 omnetpp    & 27  & 84    & 23825 \\ 
482 sphinx3    & 27  & 933   & 4503  \\ 
400.perlbench  & 46  & 288   & 41042 \\ 
445 gobmk      & 65  & 596   & 18637 \\ 
456 hmmer      & 83  & 497   & 4712  \\ 
450 soplex     & 84  & 3240  & 14583 \\ 
433.milc       & 87  & 85    & 4127  \\ 
453 povray     & 97  & 1282  & 38776 \\ 
447 dealII     & 103 & 3084  & 20518 \\ 
483 xalancbmk  & 954 & 22863 & 122611\\ 
403.gcc        & 2590& 1550  & 140904\\ 
\hline
\end{tabular}
\end{center}
\caption{
Deze tabel bevat per test case uit SPEC CPU2006 het aantal unsound sets, lege sets en het totaal aantal sets gemeten door PTAsan. Voor de complexere programma's is duidelijk een onaanvaardbaar hoog aantal unsound sets gedetecteerd. Slechts één unsound set is voldoende om ongewenste crashes te veroorzaken in \gls{dfi} of compartmentalization.
}
\end{table}

Voor programma's met slechts beperkte complexiteit zoals mcf, lbm en namd zien we dat er geen unsound sets voorkomen. Voor deze is er geen duidelijk verband tussen het totaal aantal sets en het aantal unsound sets. Dit komt omdat De testing suite samengesteld is voor benchmarks. Bijvoorbeeld namd bevat code om de interacties tussen atomen te bereken. Deze code is echter uit de codebase van NAMD\footnote{https://www.ks.uiuc.edu/Research/namd/} afgezonderd en zal dus een minder complexe control flow hebben dan NAMD zelf. Hetzelfde t voor bzip2 en benchmark.ll. Bij complexere programma's loopt het aantal unsound sets echter snel op. Dit aantal ligt onacceptabel hoog aangezien voor defensive dooleinden zoals \gls{dfi} en compartmentalization\cite{lefeuvre_sok_2024} slechts één unsound set al voor crashes of ongewenst gedrag kan zorgen. 

Verder zien we ook dat een heel aantal lege sets worden benaderd. Dit is positief aangezien SVF deze niet met zekerheid kan reduceren tot een eindige set. In de praktijk wordt een lege set aanzien als een set die alle kleuren bevat.

\subsection{Gevonden bronnen van unsoundness}

We hebben met de resultaten van PTAsan een aantal unsound access kunnen terug volgen tot hun bron. Een eerste bron van unsoundness is het incorrect afhandelen van het byval attribuut\footnote{https://llvm.org/docs/LangRef.html\#id1969} door SVF. Deze attribuut kan aan functie argumenten worden gegeven in LLVM IR en dit hierdoor wordt bij een call naar de functie steeds een kopie van dat argument genomen. SVF herkent deze attribuut niet en veronderstelt dat het object meegeven aan de functie, hetzelfde is als deze gebruikt in de functie. We zien hier dan ook dat dit object geen kleur krijgt toegekend en in geen sets vervat zit. Dit is duidelijk unsound gedrag. We hebben dit gemeld aan de ontwikkelaars van SVF en zij hebben besloten om SVF dit te laten ondersteunen\footnote{https://github.com/SVF-tools/SVF/issues/1679}.

Verder vormt de incorrecte karakterisatie van externe library functies ook een bron van unsoundness. In het bijzonder de functies die steeds een pointer naar hetzelfde object teruggeven. We zouden bij deze pointers verwachten dat SVF ze als aliasing ziet. SVF karakteriseert ze echter als `ALLOC\_STACK\_RET', als functies die een pointer terug geven naar een nieuw gealloceerd object op de stack. Functie zoals gmtime functioneren niet op deze manier dus hebben we dit ook aan de ontwikkelaars van SVF gemeld\footnote{https://github.com/SVF-tools/SVF/issues/1680}. Ze hebben sindsdien SVF ge-update om dit probleem op te lossen\footnote{https://github.com/SVF-tools/SVF/pull/1688, https://github.com/SVF-tools/SVF/pull/1693}. Ze labelen hierbij de functies correct en laten de karakterisatie van de functie het adres van een global teruggeven. Zo aliassen ze zeker en kunnen ze ook correct gekleurd worden. 

Verder vonden ten slotte nog een probleem in de constructie van de points-to sets. SVF laat voor sommige globals de link vallen tussen het element in de set en de overeenkomstige LLVM IR value. Hierdoor kunnen we de set niet volledig omvormen naar een verzameling van kleuren. Dit resulteert dus in unsoundness aangezien hierdoor sets kleuren missen. We hebben dit ook gemeld bij SVF, maar nog respons ontvangen.

Naast deze resultaten heeft PTAsan nog een lange reeks aan unsound accesses gelogd. Aangezien het traceren van de bron van de unsoundness volledig manueel gebeurt, is dit een traag proces. 

Ten slotte is het opvallend dat bovenstaande verklaringen niet in lijn zijn met de verwachte bronnen van unsoundness. De oorzaak van de gevonden bronnen ligt enkel bij bugs in SVF zelf. Aangezien SVF met voornaamste doel offensieve toepassingen is ontwikkelt, is er volgens ons een tekort aan testen binnen deze categorie. Vergelijkingen met andere toepassingen binnen deze categorie gebeurt vaak op basis van relatieve vergelijkingen, terwijl unsoundness ook bij hen voor problemen kan zorgen. Een analyse 

\section{Conclusie}

PTAsan is een sanitizer die zijn kracht toont door niet alleen een verzameling aan informatie ter beschikking stelt om de bron van unsoundness te traceren als ook garandeert dat het eerste soundness issue in de sets voor een programma gevonden kan worden. Verder hebben we met deze sanitizer aangetoond dat SVF unsound sets produceert voor variëteit aan test programma's en tot 2\% van alle sets unsound opstelt. We hebben verder de unsoundness voor ee naantal gevallen kunnen traceren tot niet de verwachte problemen, complexe programma structuren zoals relative pointers, maar tot unhandled language features, slecht gekarakteriseerde externe libraries en bugs in de analysis zelf.  

\printbibliography
\end{document}
